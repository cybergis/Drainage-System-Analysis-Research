{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;line-height:1.5em;font-size:30px;\">Notebook for A Vector Approach to Drainage Network Analysis Based on LiDAR Data</h1>\n",
    "<p style=\"text-align:center;font-size:12px;\">\n",
    "$Fangzheng$ $Lyu^{1,2}$, $Zewei$ $Xu^{1,2}$, $Xinlin$ $Ma^{3}$, $Shaohua$ $Wang^{1,2}$, $Zhiyu$ $Li^{1,2}$, $Shaowen$ $Wang^{1,2}$\n",
    "</p>\n",
    "<p style=\"text-align:center;font-size:12px;\">\n",
    "$^{1}$$Department$ $of$ $Geography$ $and$ $Geographic$ $Information$ $Science$, $University$ $of$ $Illinois$ $at$ $Urbana-Champaign$, $Urbana$, $IL$, $USA$<br>\n",
    "$^{2}$$CyberGIS$ $Center$ $for$ $Advanced$ $Digital$ $and$ $Spatial$ $Studies$, $University$ $of$ $Illinois$ $at$ $Urbana-Champaign$, $Urbana$, $IL$, $USA$<br>\n",
    "$^{3}$$Department$ $of$ $Management$ $and$ $Urban$ $Planning$, $Tsinghua$ $University$, $Beijing$, $China$<br>\n",
    "\n",
    "$Corresponding$ $Author:$ $shaowen@illinois.edu$\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drainage network analysis is fundamental to understanding the characteristics of surface hydrology. Based on elevation data, drainage network analysis is often used to extract key hydrological features like drainage networks and streamlines. Limited by raster-based data models, conventional drainage network algorithms typically allow water to flow in 4 or 8 directions (surrounding grids) from a raster grid. To resolve this limitation, this paper describes a new vector-based method for drainage network analysis that allows water to flow in any direction around each location. The method is enabled by rapid advances in Light Detection and Ranging (LiDAR) remote sensing and high-performance computing. The drainage network analysis is conducted using a high-density point cloud instead of Digital Elevation Models (DEMs) at coarse resolutions. Our computational experiments show that the vector-based method can better capture water flows without limiting the number of directions due to imprecise DEMs. Our case study applies the method to Rowan County watershed, North Carolina in the US. After comparing the drainage networks and streamlines detected with corresponding reference data from US Geological Survey generated from the Geonet software, we find that the new method performs well in capturing the characteristics of water flows on landscape surfaces in order to form an accurate drainage network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a sample notebook for running a small size dataset (from the LiDAR dataset of Rowan Watershed) with our new method for drainage system analysis. The algorithm is implemented with an execuation sample dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Psudocode](#psudocode)\n",
    "* [Set up](#chapter1)\n",
    "    * [Import Library](#section_1_1)\n",
    "    * [Set up input variables](#section_1_2)\n",
    "    * [Read LiDAR data using laspy](#section_1_3)\n",
    "* [Create a hash table](#chapter2)\n",
    "* [Elevation Function](#chapter3)\n",
    "* [Simulate the water flow](#chapter4)\n",
    "    * [Track the flow direction](#section_4_1)\n",
    "* [Visulization](#chapter5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Psudocode <img src=\"Picture1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up <a class=\"anchor\" id=\"chapter1\"></a>\n",
    "The Library used for in the algorithm is set up here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Library & Import Library <a class=\"anchor\" id=\"section_1_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flake8\n",
      "  Downloading flake8-3.9.2-py2.py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 1.6 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting pycodestyle_magic\n",
      "  Downloading pycodestyle_magic-0.5-py2.py3-none-any.whl (9.5 kB)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from flake8) (1.5.0)\n",
      "Collecting mccabe<0.7.0,>=0.6.0\n",
      "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
      "Collecting pyflakes<2.4.0,>=2.3.0\n",
      "  Downloading pyflakes-2.3.1-py2.py3-none-any.whl (68 kB)\n",
      "\u001b[K     |████████████████████████████████| 68 kB 6.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pycodestyle<2.8.0,>=2.7.0\n",
      "  Downloading pycodestyle-2.7.0-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[K     |████████████████████████████████| 41 kB 650 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->flake8) (3.1.0)\n",
      "Installing collected packages: mccabe, pyflakes, pycodestyle, flake8, pycodestyle-magic\n",
      "Successfully installed flake8-3.9.2 mccabe-0.6.1 pycodestyle-2.7.0 pycodestyle-magic-0.5 pyflakes-2.3.1\n"
     ]
    }
   ],
   "source": [
    "# pep8 check\n",
    "!pip install flake8 pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting laspy==1.7.0\n",
      "  Downloading laspy-1.7.0-py2.py3-none-any.whl (489 kB)\n",
      "\u001b[K     |████████████████████████████████| 489 kB 10.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gdown==3.13.0\n",
      "  Downloading gdown-3.13.0.tar.gz (9.3 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from laspy==1.7.0) (1.18.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown==3.13.0) (1.14.0)\n",
      "Requirement already satisfied: requests[socks]>=2.12.0 in /opt/conda/lib/python3.7/site-packages (from gdown==3.13.0) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown==3.13.0) (4.45.0)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.12.0->gdown==3.13.0) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.12.0->gdown==3.13.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.12.0->gdown==3.13.0) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.12.0->gdown==3.13.0) (1.25.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.12.0->gdown==3.13.0) (1.7.1)\n",
      "Building wheels for collected packages: gdown\n",
      "  Building wheel for gdown (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gdown: filename=gdown-3.13.0-py3-none-any.whl size=9033 sha256=af1b3deff40d443e2550cab1dd638dcf7b0c2b6897ca769b7551986d4fbe2bbc\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/2f/2a/2f/86449b6bdbaa9aef873f68332b68be6bfbc386b9219f47157d\n",
      "Successfully built gdown\n",
      "Installing collected packages: laspy, filelock, gdown\n",
      "Successfully installed filelock-3.0.12 gdown-3.13.0 laspy-1.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install laspy==1.7.0 gdown==3.13.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import laspy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import inv\n",
    "import math\n",
    "import datetime\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up input variables <a class=\"anchor\" id=\"section_1_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3:1: E266 too many leading '#' for block comment\n"
     ]
    }
   ],
   "source": [
    "# var1 is the starting location in the x-axis\n",
    "# var2 is the starting location in the y-axis\n",
    "## var3 is the angle different we want\n",
    "var1 = 5\n",
    "var2 = 5\n",
    "var3 = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare sample LiDAR data <a class=\"anchor\" id=\"section_1_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8:80: E501 line too long (93 > 79 characters)\n",
      "14:80: E501 line too long (87 > 79 characters)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    "import gdown\n",
    "\n",
    "local_sample_path = \"./3_2.las\"\n",
    "if not os.path.isfile(local_sample_path):\n",
    "    print(\"Missing sample data!\")\n",
    "    sample_shared = \"/home/jovyan/shared_data/data/drainage_system_analysis_research/3_2.las\"\n",
    "    if os.path.join(sample_shared):\n",
    "        print(\"Copying sample data from shared folder...\")\n",
    "        copyfile(sample_shared, local_sample_path)\n",
    "    else:\n",
    "        print(\"Copying sample data from shared google drive...\")\n",
    "        url_gdrive = 'https://drive.google.com/uc?id=1JOl1IylIZg72QdMM89xs10NLFk4rObml'\n",
    "        gdown.download(url_gdrive, local_sample_path, quiet=False)\n",
    "else:\n",
    "    print(\"Sample data already exists\")\n",
    "if not os.path.isfile(local_sample_path):\n",
    "    print(\"Can not retrieve sample data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {local_sample_path} -alh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read LiDAR data using laspy <a class=\"anchor\" id=\"section_1_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1:1: E266 too many leading '#' for block comment\n",
      "3:1: E266 too many leading '#' for block comment\n",
      "7:1: E266 too many leading '#' for block comment\n",
      "8:11: E225 missing whitespace around operator\n",
      "9:11: E225 missing whitespace around operator\n"
     ]
    }
   ],
   "source": [
    "## Store the LiDAR data as infile\n",
    "infile = laspy.file.File(local_sample_path, mode=\"r\")\n",
    "## Get the value for x axis, y axis, and elevation for LiDAR point cloud\n",
    "ground_x = infile.x\n",
    "ground_y = infile.y\n",
    "ground_z = infile.z\n",
    "## Normalize the output for the LiDAR file\n",
    "ground_x_2=ground_x-ground_x.min()\n",
    "ground_y_2=ground_y-ground_y.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total amount of LiDAR point in the LiDAR file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5546582"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The x, y, z value for points in the LiDAR file are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ground_x_2\n",
    "y = ground_y_2\n",
    "z = ground_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a dictionary to store the datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1:27: E231 missing whitespace after ','\n",
      "1:29: E231 missing whitespace after ','\n",
      "2:11: E225 missing whitespace around operator\n",
      "2:71: E231 missing whitespace after ','\n",
      "2:80: E501 line too long (87 > 79 characters)\n"
     ]
    }
   ],
   "source": [
    "threedarray = np.vstack((x,y,z)).T\n",
    "dictionary=pd.Series(threedarray.tolist(), index=map(lambda a: round(a,2), x.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of the format of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.11     [1.1100000001024455, 238.38000000000466, 690.64]\n",
       "1.11     [1.1100000001024455, 357.63000000000466, 691.02]\n",
       "1.11     [1.1100000001024455, 493.71999999997206, 695.84]\n",
       "1.11     [1.1100000001024455, 510.03000000002794, 695.94]\n",
       "1.11    [1.1100000001024455, 543.7900000000373, 694.55...\n",
       "1.11      [1.1100000001024455, 608.5899999999674, 694.42]\n",
       "1.11      [1.1100000001024455, 668.1500000000233, 698.37]\n",
       "1.11      [1.1100000001024455, 804.5600000000559, 698.38]\n",
       "1.11      [1.1100000001024455, 803.4599999999627, 698.38]\n",
       "1.11      [1.1100000001024455, 795.9000000000233, 698.37]\n",
       "1.11      [1.1100000001024455, 829.4000000000233, 698.32]\n",
       "1.11      [1.1100000001024455, 843.5400000000373, 697.71]\n",
       "1.11       [1.1100000001024455, 850.109999999986, 697.59]\n",
       "1.11                 [1.1100000001024455, 899.75, 699.48]\n",
       "1.11      [1.1100000001024455, 927.9899999999907, 699.64]\n",
       "1.11      [1.1100000001024455, 1039.5100000000093, 699.7]\n",
       "1.11     [1.1100000001024455, 1207.2900000000373, 703.09]\n",
       "1.11                [1.1100000001024455, 1221.25, 704.29]\n",
       "1.11     [1.1100000001024455, 1261.1600000000326, 707.38]\n",
       "1.11      [1.1100000001024455, 1298.140000000014, 707.98]\n",
       "1.11      [1.1100000001024455, 1284.0899999999674, 707.6]\n",
       "1.11      [1.1100000001024455, 1332.920000000042, 708.77]\n",
       "1.11      [1.1100000001024455, 1338.140000000014, 708.79]\n",
       "1.11      [1.1100000001024455, 1457.170000000042, 711.67]\n",
       "1.11      [1.1100000001024455, 1442.109999999986, 711.32]\n",
       "1.11      [1.1100000001024455, 1463.6600000000326, 711.9]\n",
       "1.11    [1.1100000001024455, 1756.0500000000466, 712.6...\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[1.11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a hash table data structure to store the LiDAR data <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the index for each LiDAR data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1:7: E225 missing whitespace around operator\n",
      "2:7: E225 missing whitespace around operator\n",
      "3:11: E225 missing whitespace around operator\n"
     ]
    }
   ],
   "source": [
    "list_a=map(lambda a: 10000*int(a), x.tolist())\n",
    "list_b=map(lambda a: int(a), y.tolist())\n",
    "index_list=[sum(x) for x in zip(list_a, list_b)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the hash table and use dictionary data structure to store the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1:16: E225 missing whitespace around operator\n"
     ]
    }
   ],
   "source": [
    "grid_dictionary=pd.Series(threedarray.tolist(), index=index_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a overview of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16        [0.02000000001862645, 16.46999999997206, 688.92]\n",
       "6              [0.0, 6.800000000046566, 688.9300000000001]\n",
       "28                       [0.0, 28.400000000023283, 688.96]\n",
       "280008     [28.010000000009313, 8.900000000023283, 689.47]\n",
       "60002       [6.370000000111759, 2.2800000000279397, 689.0]\n",
       "                                ...                       \n",
       "352542      [35.6500000001397, 2542.0200000000186, 702.96]\n",
       "322542     [32.199999999953434, 2542.030000000028, 702.85]\n",
       "372542       [37.40999999991618, 2542.930000000051, 703.2]\n",
       "372547                  [37.75, 2547.359999999986, 703.51]\n",
       "482542      [48.47999999998137, 2542.0200000000186, 704.2]\n",
       "Length: 5546582, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to find the elevation  <a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the function used in the algorithm to find the elevation of any given point (x, y) using bilinear interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2:5: E265 block comment should start with '# '\n",
      "5:9: E225 missing whitespace around operator\n",
      "6:23: E225 missing whitespace around operator\n",
      "7:9: E266 too many leading '#' for block comment\n",
      "9:9: E266 too many leading '#' for block comment\n",
      "12:22: E225 missing whitespace around operator\n",
      "12:40: E225 missing whitespace around operator\n",
      "12:58: E225 missing whitespace around operator\n",
      "12:76: E225 missing whitespace around operator\n",
      "12:80: E501 line too long (90 > 79 characters)\n",
      "15:37: E225 missing whitespace around operator\n",
      "18:46: E231 missing whitespace after ','\n",
      "20:21: E722 do not use bare 'except'\n",
      "21:32: E225 missing whitespace around operator\n",
      "23:35: E225 missing whitespace around operator\n",
      "24:13: E266 too many leading '#' for block comment\n",
      "25:29: E231 missing whitespace after ','\n",
      "28:14: E225 missing whitespace around operator\n",
      "29:31: E225 missing whitespace around operator\n",
      "31:18: E225 missing whitespace around operator\n",
      "33:5: E266 too many leading '#' for block comment\n",
      "35:6: E225 missing whitespace around operator\n",
      "35:10: E231 missing whitespace after ','\n",
      "35:28: E231 missing whitespace after ','\n",
      "35:46: E231 missing whitespace after ','\n",
      "35:80: E501 line too long (83 > 79 characters)\n",
      "36:10: E231 missing whitespace after ','\n",
      "36:28: E231 missing whitespace after ','\n",
      "36:46: E231 missing whitespace after ','\n",
      "36:80: E501 line too long (83 > 79 characters)\n",
      "37:10: E231 missing whitespace after ','\n",
      "37:28: E231 missing whitespace after ','\n",
      "37:46: E231 missing whitespace after ','\n",
      "37:80: E501 line too long (83 > 79 characters)\n",
      "38:10: E231 missing whitespace after ','\n",
      "38:28: E231 missing whitespace after ','\n",
      "38:46: E231 missing whitespace after ','\n",
      "38:80: E501 line too long (83 > 79 characters)\n",
      "39:6: E225 missing whitespace around operator\n",
      "39:63: E231 missing whitespace after ','\n",
      "39:80: E501 line too long (81 > 79 characters)\n",
      "41:9: E266 too many leading '#' for block comment\n",
      "43:80: E501 line too long (80 > 79 characters)\n",
      "45:5: E722 do not use bare 'except'\n"
     ]
    }
   ],
   "source": [
    "def find_elevation_new(x, y):\n",
    "    #bilinear interpolation\n",
    "    storage = []\n",
    "    curr_index = 10000*int(x)+int(y)\n",
    "    diff= 0\n",
    "    while(len(storage)<4):\n",
    "        ## Find all the data within the nearby grid\n",
    "        temp = []\n",
    "        ## For loop here to find candidate points for bilinear interpolation\n",
    "        for i in range(int(x-diff), int(x+diff+1)):\n",
    "            for j in range(int(y-diff), int(y+diff+1)):\n",
    "                if (i==int(x-diff) or i==int(x+diff) or j==int(y-diff) or j==int(y+diff)):\n",
    "                    try:\n",
    "                        rt = grid_dictionary[10000*i+j]\n",
    "                        if (type(rt)==list):\n",
    "                            temp.append(rt)\n",
    "                        else:\n",
    "                            for it in range(0,len(rt)):\n",
    "                                temp.append(rt[it])\n",
    "                    except:\n",
    "                        useless=1\n",
    "        temp.sort(key=lambda e: (e[0]-x)*(e[0]-x)+(e[1]-y)*(e[1]-y))\n",
    "        if (len(storage)+len(temp)<=4):\n",
    "            ## add them\n",
    "            for i in range(0,len(temp)):\n",
    "                storage.append(temp[i])\n",
    "        else:\n",
    "            k=0\n",
    "            while(len(storage)!=4):\n",
    "                storage.append(temp[k])\n",
    "                k=k+1\n",
    "        diff = diff+1\n",
    "    ## find the points used for data interpolation\n",
    "    new_storage = storage[:4]\n",
    "    a=[[1,new_storage[0][0],new_storage[0][1],new_storage[0][0]*new_storage[0][1]],\n",
    "       [1,new_storage[1][0],new_storage[1][1],new_storage[1][0]*new_storage[1][1]],\n",
    "       [1,new_storage[2][0],new_storage[2][1],new_storage[2][0]*new_storage[2][1]],\n",
    "       [1,new_storage[3][0],new_storage[3][1],new_storage[3][0]*new_storage[3][1]]]\n",
    "    b=[new_storage[0][2], new_storage[1][2], new_storage[2][2],new_storage[3][2]]\n",
    "    try:\n",
    "        ## Conduct bilinear interpolation\n",
    "        coef_matrix = np.matmul(inv(a), b)\n",
    "        rt = coef_matrix[0]+coef_matrix[1]*x+coef_matrix[2]*y+coef_matrix[3]*x*y\n",
    "        return rt\n",
    "    except:\n",
    "        return 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate the water flow <a class=\"anchor\" id=\"chapter4\"></a>\n",
    "This is the major step in the algorithm that is used for simulation of the water flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The area_length variable here represents how large the area the users want to calculate.\n",
    "area_length = 10\n",
    "\n",
    "## Print the current time before the execution of the algorithm\n",
    "print(datetime.datetime.now())\n",
    "min_x = var1*100\n",
    "min_y = var2*100\n",
    "max_x = var1*100+area_length\n",
    "max_y = var2*100+area_length\n",
    "increment = 1\n",
    "angle = var3\n",
    "x_coord = min_x\n",
    "y_coord = min_y\n",
    "rt = []\n",
    "while x_coord!=(max_x+1):\n",
    "    while y_coord!=(max_y+1):\n",
    "        ## find the elevation of the current coordinate\n",
    "        curr_elevation = find_elevation_new(x_coord, y_coord)\n",
    "        curr_x = x_coord\n",
    "        curr_y = y_coord\n",
    "        #print(\"Starting Point:\")\n",
    "        print((curr_x,curr_y))\n",
    "        curr_array = []\n",
    "        while ((curr_x>=min_x and curr_x<=max_x) and (curr_y>=min_y and curr_y<=max_y)):\n",
    "            #print((curr_x, curr_y, curr_elevation))\n",
    "            curr_array.append((curr_x, curr_y))\n",
    "            rt_x = curr_x\n",
    "            rt_y = curr_y\n",
    "            rt_elevation = curr_elevation\n",
    "            angel_diff = 0\n",
    "            ## find the elevation of all candidate points\n",
    "            while(angel_diff<360):\n",
    "                new_x = curr_x+increment*math.sin(math.pi/180*angel_diff)\n",
    "                new_y = curr_y+increment*math.cos(math.pi/180*angel_diff)\n",
    "                new_elevation = find_elevation_new(new_x, new_y)\n",
    "                #print((angel_diff,new_x,new_y,new_elevation,rt_x,rt_y,rt_elevation))\n",
    "                if (new_elevation<rt_elevation):\n",
    "                    rt_x = new_x\n",
    "                    rt_y = new_y\n",
    "                    rt_elevation = new_elevation\n",
    "                angel_diff = angel_diff+angle\n",
    "            ## Check if the data is a pit or not\n",
    "            if (rt_elevation<curr_elevation):\n",
    "                curr_x = rt_x\n",
    "                curr_y = rt_y\n",
    "                curr_elevation = rt_elevation\n",
    "            else:\n",
    "                break\n",
    "        rt.append(curr_array)\n",
    "        #print(\"Result For:\")\n",
    "        #print((x_coord,y_coord))\n",
    "        #print(curr_array)\n",
    "        y_coord=y_coord+1\n",
    "    y_coord = min_y\n",
    "    x_coord=x_coord+1\n",
    "## Print the end time of the execution\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the simulated water flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(rt)\n",
    "    \n",
    "data = []\n",
    "## Print the simulated waterflow\n",
    "for i in range(0,area_length+1):\n",
    "    data.append([0]*(area_length+1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track the flow direction <a class=\"anchor\" id=\"section_4_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(rt)):\n",
    "    for j in range(0,len(rt[i])):\n",
    "        data[int(math.floor(rt[i][j][0]))-var1*100][int(math.floor(rt[i][j][1]))-var2*100]=data[int(math.floor(rt[i][j][0]))-var1*100][int(math.floor(rt[i][j][1]))-var2*100]+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulization<a class=\"anchor\" id=\"chapter5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result after tracking the water direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple visulization of the result, with brighter area having more water flowing through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(data, interpolation='none')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
